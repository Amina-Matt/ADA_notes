{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b1a8f76-6d8c-42a2-82a8-ac423eecffbe",
   "metadata": {},
   "source": [
    "# Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575dfd3a-3df1-4a2c-b85e-26c6e98571b4",
   "metadata": {},
   "source": [
    "## Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083a699c-3d93-4cc2-b387-0d3bfd9f419b",
   "metadata": {},
   "source": [
    "In bootstrapping you sample WITH replacement an original sample to have some statistics about it. \n",
    "For example if we have only a sample for femal and male, and want to have sosme statistics about the difference,let's do this.\n",
    "\n",
    "We want to calculate N_replicas values of the variable of interest, i.e. here DIFF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88212ab-81f3-4f27-a7b1-747c198b3233",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = [] #variable of interest\n",
    "\n",
    "for i in range(n_replicas): #we do it n_replicas times \n",
    "\n",
    "sample = families.sample(frac=1.0, replace=True) # we get a sample woth the same size and with REPLACEMENT\n",
    " \n",
    "male_sample_mean = sample[sample.gender == ‘male’].childHeight.mean()\n",
    "female_sample_mean = sample[sample.gender == ‘female’].childHeight.mean()\n",
    "\n",
    "diffs.append(male_sample_mean — female_sample_mean) #we add the value calculate with this SAM\n",
    "\n",
    "\n",
    "diffs = pd.Series(diffs)\n",
    "plot_hist(diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e47c5-435d-422f-9def-5b0ab48cd1c3",
   "metadata": {},
   "source": [
    "## Fitting model \n",
    "`DECLARE`   \n",
    "`mod = smf.logit(formula = '' )`    \n",
    "`mod = smf.ols(formula = '')`  \n",
    "`FIT`  \n",
    "`res = mod.fit()`   \n",
    "`SUMMARY`  \n",
    "`print(res.summary())`  \n",
    "\n",
    "Note:\n",
    "- if p>0.05 then the coefficient is not statistically significant.\n",
    "- a coefficient can decrease for a predictor when we add another predictor if it was acting as a proxy for this one (disaggregate)\n",
    "- if the dependant variable is (instead of y) log(y) then we don't add the coefficient to the outcome but the outcome is multiplied by EXP(coefficient)\n",
    "\n",
    "### Syntax\n",
    "`np.log()  `  \n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a87164-446e-49c9-a808-41dd1b9af4c4",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "CLEAN  \n",
    "CREATE   \n",
    "FIT//TRAIN  \n",
    "    - `lin_ref.coef_`  \n",
    "    - `lin_reg.intercept_`  \n",
    "    \n",
    "PREDICT\n",
    "  - `cross_val_predict()` \n",
    "  - `cross_val_score()`\n",
    "  - `mean_squared_error`  \n",
    "\n",
    "CHECK \n",
    "- plot of original versus predicted \n",
    "- confusion matrix\n",
    "    Recall: avoid false positives\n",
    "    Precision: avoid false negatives\n",
    "- `roc curve `  \n",
    "- `auc `\n",
    "\n",
    "\n",
    "NOTES \n",
    " - REGULARIZATION : ridge regression use a penalty to reduce model complexity in case of a small training set\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e9d0b2-bad2-43f4-8e7f-35b03e8c2acb",
   "metadata": {},
   "source": [
    "## Propensity score \n",
    "The propensity score is used to address selection bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d711ebd-bf3a-4cd5-85d5-4bb28d8598da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity calculation \n",
    "def similarity(prop_score_1, prop_score_2):\n",
    "    score = 1- np.abs(prop_score_1, prop_score_2)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06aa657-b24f-4a75-991c-cbad802d71d4",
   "metadata": {},
   "source": [
    "**Visualize control vs treated**  \n",
    " `sns.distplot()`  \n",
    " `df.boxplot()`  \n",
    " `sns.pairplot()`  \n",
    " `ax = ...`    \n",
    " `ax = ...`  \n",
    " `ax.set(title...)`  \n",
    " `plt.legend()`  \n",
    " `plt.show()` \n",
    " \n",
    "**Propensity score calculations**  \n",
    "- STANDARDIZE \n",
    "     - x' = (x-xmean)/(std)\n",
    " - DESCRIBE \n",
    "     - /!\\ in the formula TREAT is the variable we want to predict\n",
    " - FIT\n",
    " - PREDICT   \n",
    "   `res.predict()`  \n",
    " \n",
    "**Propensity score matching**  \n",
    " `networkx.nx` \n",
    " - SEPARATE control/treat\n",
    " - INITIALIZE graph\n",
    " - LOOP and ADD edges (with condition if one is difficult to include)\n",
    " - MAXIMIZE \n",
    "  `G.add_weight_edges_from()`  \n",
    " `nx.max_weight_matching(G)`\n",
    " \n",
    "   \n",
    " \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389b52f2-3773-414a-9636-9b3b81f7eb57",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION\n",
    "\n",
    "Logistic regression i sused to fit variables that are binary, exemple old and young, or male or female.\n",
    "There is a threshold that goes with it, usually at 0.5 to go from the probability to the classification. \n",
    "\n",
    "\n",
    "- [ X ] Feature matrix \n",
    "- y   \n",
    "CLEAN   \n",
    "    - categorical into dummies\n",
    "    - replace na values  \n",
    "    `X = pd.get_dummies(titanic[titanic_features])`  \n",
    "    `X = X.fillna(X.mean())`  \n",
    "CREATE  \n",
    "    - model   \n",
    "        `lr = LinearRegression() `  \n",
    "        `logistic = LogisticRegression(solver='lbfgs')` \n",
    "\n",
    "TRAIN  \n",
    "     `clf.fit(X, y)`  \n",
    "     `cross_val_score(clf...)`  can be done on the training ?or testing? set\n",
    "PREDICT  \n",
    "    `res.predict`  \n",
    "    `res.predict_proba()`  \n",
    "    `roc_curve()`  \n",
    "    \n",
    "**Note**\n",
    "Fit on the training set  \n",
    "`clf = LogisticRegression(random_state=0, solver='lbfgs',C = 10).fit(X_train,Y_train)`\n",
    "\n",
    "Predict on the test set  \n",
    "`print('Accuracy:',clf.score(X_test,Y_test))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2770ae7-e35c-4ee8-98fa-c24acecebe05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa19535e-9d83-4cfb-9c0c-48f4168099a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Log and odds\n",
    "The probability is linked to an odd, which is then converted in log odds.\n",
    "NB: this means that the coefficient in the regression is linked to an increase in log odds (and not directly the probability) of coeff. \n",
    "\n",
    "The expression below allows to link an initial probablity and an incres in logg odds equals to coeff. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f29c26-1ec4-4576-8f39-195a46b801e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_to_log_odds(p):\n",
    "    return np.log(p/(1-p))\n",
    "def log_odds_to_p(odds):\n",
    "    return np.exp(odds) / (1+ np.exp(odds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5603482-b12e-447d-a913-4b7f924b2198",
   "metadata": {},
   "source": [
    "# Applied ML\n",
    "\n",
    "1. DROP NA  \n",
    "    - `dropna(inplace=True)`  \n",
    "2. PREDICTION IN 0,1 instead of CAT\n",
    "    - change to 0,1 if multiples outcomes (alive, dead, injured, missing...) and drop the initial categories\n",
    "3. SPLIT dataset\n",
    "    - with `sklearn` use `X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)`  \n",
    "    - without external librairies use  `mask = np.random.rand(len(data_to_split))<ratio` with ratio =0.8\n",
    "    \n",
    "4. CONVERT CATEGORICAL from TRAIN \n",
    "    - start with the TRAIN test  \n",
    "    - do the same with TEST but select ONLY categorical columns `test=pd.get_dummies(test,column=cat_colums)`**[train_categorical.columns]**\n",
    "5. STANDARDIZE for numerical columns \n",
    "    - create a function that use MEAN and STD from TRAIN \n",
    "6. PREDICT\n",
    "    - `logistic.fit(train_features_std,train_label)`  \n",
    "    - `prediction_proba = logistic.predict_proba(test_features_std)`\n",
    "\n",
    "\n",
    "Notes : \n",
    "- F1 is a value that contains both the RECALL and the PRECISION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c0e230-989e-4be8-86eb-1e4e1a100594",
   "metadata": {},
   "source": [
    "## KNN \n",
    "- Define K  \n",
    "`KneighborsClassifier(n_neighbors=5)`\n",
    "- Fit  \n",
    "`mod.fit`  \n",
    "- Predict and score   \n",
    "    - use mean  \n",
    "`mod.predict()`  \n",
    "`cross_val_score(    ,scoring=precision)`  \n",
    "`cross_val_score(    ,scoring=recall)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cca7762-1543-4250-be91-6e959a10edc9",
   "metadata": {},
   "source": [
    "## Random Forest \n",
    "`clf = RandomForestClassifier(max_depth=3, random_state=0, n_estimators=nt)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec02ac5e-77d0-4bb9-8ea0-86fdac458d21",
   "metadata": {},
   "source": [
    "## Tuples\n",
    "`list_of_tuples = list(zip(clf.coef_[0],vectorizer.get_feature_names()))`  \n",
    "\n",
    "\n",
    "`list_of_tuples.sort(key=lambda x:x[0])`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8733975e-37bb-4c29-9fbb-ed3fd0862be5",
   "metadata": {},
   "source": [
    "## FOR syntax inline\n",
    "`doc = [token for token in doc if token not in STOPWORDS and len(token) > 2]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7413daa2-f578-44b7-b38d-8046a84fdede",
   "metadata": {},
   "source": [
    "## SPARK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fffc58c-9353-489e-b798-8eb767c43590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the AGG is the key \n",
    "\n",
    "subreddits_authors = reddit_posts.groupBy(['subreddit']).agg(\\\n",
    "    count('*').alias('Total Messages'),\n",
    "    countDistinct('author').alias('Total Authors'),\n",
    "    mean(length('body')).alias('Message Average Length') )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdb8e1dc-a8d9-45cc-beaf-4cb94fcf4e0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reddit_with_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3v/cd3_rvz10bd1jd08x0c03tpr0000gt/T/ipykernel_3538/2718168122.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# EXPLODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreddit_with_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"words\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'reddit_with_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "# EXPLODE\n",
    "all_words = reddit_with_tokens.select(explode(\"words\").alias(\"word\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876288bc-8c55-486a-a6ca-cb29d71f9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_50k = filtered_tokens.rdd.map(lambda r: (r.subreddit, [r.word])).reduceByKey(lambda a,b: a+b).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91724f39-cd7a-49ac-aef6-8ba9b0fad734",
   "metadata": {},
   "source": [
    "rdd.map map function through an object in Spark. \n",
    "The reduceByKey() group by key and reduce (with sum by default)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a2fbdf-f720-4bf7-858e-01c855ba876a",
   "metadata": {},
   "source": [
    "## Performance \n",
    "\n",
    "Accuracy : \n",
    "Accuracy is a bad metric if there is  **class** imbalance. It is very easy for accuracy to be biased. If you label everything as the majority class, the accuracy would still be very high (in the high 90s), but the performance on the minority class would be terrible.\n",
    "\n",
    "In such cases, one can use the either of the following for evaluation.\n",
    "- confusion matrix `confusion_matrix`  \n",
    "- balanced accuracy score (sklearn) `balanced_accuracy_score`  \n",
    "- (un)weighted micro/macro averaged F1 scores  `classification_report` \n",
    "- 'balanced' class weights `class_weights = balanced` while training the model forces the loss function to give higher relative importance to training samples corresponding to the minority class. Actually, the training samples are weighted as inverse of the class proportions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6b8a4a-d32c-44b6-a77f-a21194c00b58",
   "metadata": {},
   "source": [
    "#### Confusion matrix\n",
    "One row per classification \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a561e513-4bcb-4e07-97e4-79f9a395a355",
   "metadata": {},
   "source": [
    "#### Minority  \n",
    "The model didn't see enough training data from the minority class to learn to classify/discriminate it.\n",
    "The loss function treats each training sample as equally important. Thus, trying to minimize the overall loss would guide the model to focus more on the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cfc9db-b865-492e-8a86-3b5e57a68337",
   "metadata": {},
   "source": [
    "# NETWORK \n",
    "CREATE from Pandas  \n",
    "`nx.from_pandas_edgelist(edges, 'Source', 'Target', edge_attr=None, create_using= nx.Graph())`\n",
    "\n",
    "**/!\\\\** attention if DIRECTED Graph then DiGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fac0ed8-9a81-4807-8105-17c0d7743b24",
   "metadata": {},
   "source": [
    "graph.degree() digraph -> * 1/2 OR len(graph.edges())/len(graph.nodes()) directly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2749d754-bab9-4039-9e77-93adef9e45e3",
   "metadata": {},
   "source": [
    "If linear in log log \n",
    " -> distribution follows powerlaw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79f07d4-2388-4919-b341-0aa7356eed21",
   "metadata": {},
   "source": [
    "***Heavy-tailed data: power laws***  \n",
    "straight line on log-log axes:  \n",
    "    Very large values are rare, “but not very rare”  \n",
    "    Many natural phenomena are power laws (e.g., # of friends)  \n",
    "    For dealing with them, need to know some tricks  \n",
    "    E.g., for small α, mean & var = ∞ → use median!  \n",
    "  \n",
    "y = C x–α   ↔  log(y) = log(C) – α log(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fc88663-c402-4081-b543-e9906f8ff52b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'is_weakly_connected' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3v/cd3_rvz10bd1jd08x0c03tpr0000gt/T/ipykernel_1551/4087147305.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mis_weakly_connected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'is_weakly_connected' is not defined"
     ]
    }
   ],
   "source": [
    "is_weakly_connected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7155ed5-1b04-4859-87c0-7732fb70d36f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
