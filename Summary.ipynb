{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b1a8f76-6d8c-42a2-82a8-ac423eecffbe",
   "metadata": {},
   "source": [
    "# Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575dfd3a-3df1-4a2c-b85e-26c6e98571b4",
   "metadata": {},
   "source": [
    "## Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083a699c-3d93-4cc2-b387-0d3bfd9f419b",
   "metadata": {},
   "source": [
    "In bootstrapping you sample WITH replacement an original sample to have some statistics about it. \n",
    "For example if we have only a sample for femal and male, and want to have sosme statistics about the difference,let's do this.\n",
    "\n",
    "We want to calculate N_replicas values of the variable of interest, i.e. here DIFF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88212ab-81f3-4f27-a7b1-747c198b3233",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = [] #variable of interest\n",
    "\n",
    "for i in range(n_replicas): #we do it n_replicas times \n",
    "\n",
    "sample = families.sample(frac=1.0, replace=True) # we get a sample woth the same size and with REPLACEMENT\n",
    " \n",
    "male_sample_mean = sample[sample.gender == ‘male’].childHeight.mean()\n",
    "female_sample_mean = sample[sample.gender == ‘female’].childHeight.mean()\n",
    "\n",
    "diffs.append(male_sample_mean — female_sample_mean) #we add the value calculate with this SAM\n",
    "\n",
    "\n",
    "diffs = pd.Series(diffs)\n",
    "plot_hist(diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa19535e-9d83-4cfb-9c0c-48f4168099a7",
   "metadata": {},
   "source": [
    "## Log and odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f29c26-1ec4-4576-8f39-195a46b801e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_to_log_odds(p):\n",
    "    return np.log(p/(1-p))\n",
    "def log_odds_to_p(odds):\n",
    "    return np.exp(odds) / (1+ np.exp(odds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e47c5-435d-422f-9def-5b0ab48cd1c3",
   "metadata": {},
   "source": [
    "## Fitting model \n",
    "`DECLARE`   \n",
    "`mod = smf.logit(formula = '' )`    \n",
    "`mod = smf.ols(formula = '')`  \n",
    "`FIT`  \n",
    "`res = mod.fit()`   \n",
    "`SUMMARY`  \n",
    "`print(res.summary())`  \n",
    "\n",
    "Note:\n",
    "- if p>0.05 then the coefficient is not statistically significant.\n",
    "- a coefficient can decrease for a predictor when we add another predictor if it was acting as a proxy for this one (disaggregate)\n",
    "- if the dependant variable is (instead of y) log(y) then we don't add the coefficient to the outcome but the outcome is multiplied by EXP(coefficient)\n",
    "\n",
    "### Syntax\n",
    "`np.log()  `  \n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e9d0b2-bad2-43f4-8e7f-35b03e8c2acb",
   "metadata": {},
   "source": [
    "## Propensity score \n",
    "The propensity score is used to address selection bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d711ebd-bf3a-4cd5-85d5-4bb28d8598da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity calculation \n",
    "def similarity(prop_score_1, prop_score_2):\n",
    "    score = 1- np.abs(prop_score_1, prop_score_2)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06aa657-b24f-4a75-991c-cbad802d71d4",
   "metadata": {},
   "source": [
    "**Visualize control vs treated**  \n",
    " `sns.distplot()`  \n",
    " `df.boxplot()`  \n",
    " `sns.pairplot()`  \n",
    " `ax = ...`    \n",
    " `ax = ...`  \n",
    " `ax.set(title...)`  \n",
    " `plt.legend()`  \n",
    " `plt.show()` \n",
    " \n",
    "**Propensity score calculations**  \n",
    "- STANDARDIZE \n",
    "     - x' = (x-xmean)/(std)\n",
    " - DESCRIBE \n",
    "     - /!\\ in the formula TREAT is the variable we want to predict\n",
    " - FIT\n",
    " - PREDICT   \n",
    "   `res.predict()`  \n",
    " \n",
    "**Propensity score matching**  \n",
    " `networkx.nx` \n",
    " - SEPARATE\n",
    " - INITIALIZE graph\n",
    " - LOOP and ADD edges (with condition if one is difficult to include)\n",
    " - MAXIMIZE \n",
    "  `G.add_weight_edges_from()`  \n",
    " `nx.max_weight_matching(G)`\n",
    " \n",
    "   \n",
    " \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389b52f2-3773-414a-9636-9b3b81f7eb57",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION\n",
    "- [ X ] Feature matrix \n",
    "- y   \n",
    "CLEAN   \n",
    "    - categorical into dummies\n",
    "    - replace na values  \n",
    "    `X = pd.get_dummies(titanic[titanic_features])`  \n",
    "    `X = X.fillna(X.mean())`  \n",
    "CREATE  \n",
    "    - model   \n",
    "        `lr = LinearRegression() `  \n",
    "        `logistic = LogisticRegression(solver='lbfgs')` \n",
    "\n",
    "TRAIN  \n",
    "     `clf.fit(X, y)`  \n",
    "     `cross_val_score(clf...)`  can be done on the training ?or testing? set\n",
    "PREDICT  \n",
    "    `res.predict`  \n",
    "    `res.predict_proba()`  \n",
    "    `roc_curve()`  \n",
    "    \n",
    "**Note**\n",
    "Fit on the training set  \n",
    "`clf = LogisticRegression(random_state=0, solver='lbfgs',C = 10).fit(X_train,Y_train)`\n",
    "\n",
    "Predict on the test set  \n",
    "`print('Accuracy:',clf.score(X_test,Y_test))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c0e230-989e-4be8-86eb-1e4e1a100594",
   "metadata": {},
   "source": [
    "## KNN \n",
    "- Define K  \n",
    "`KneighborsClassifier(n_neighbors=5)`\n",
    "- Fit  \n",
    "`mod.fit`  \n",
    "- Predict and score   \n",
    "    - use mean  \n",
    "`mod.predict()`  \n",
    "`cross_val_score(    ,scoring=precision)`  \n",
    "`cross_val_score(    ,scoring=recall)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cca7762-1543-4250-be91-6e959a10edc9",
   "metadata": {},
   "source": [
    "## Random Forest \n",
    "`clf = RandomForestClassifier(max_depth=3, random_state=0, n_estimators=nt)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec02ac5e-77d0-4bb9-8ea0-86fdac458d21",
   "metadata": {},
   "source": [
    "## Tuples\n",
    "`list_of_tuples = list(zip(clf.coef_[0],vectorizer.get_feature_names()))`  \n",
    "\n",
    "\n",
    "`list_of_tuples.sort(key=lambda x:x[0])`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8733975e-37bb-4c29-9fbb-ed3fd0862be5",
   "metadata": {},
   "source": [
    "## FOR syntax inline\n",
    "`doc = [token for token in doc if token not in STOPWORDS and len(token) > 2]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7413daa2-f578-44b7-b38d-8046a84fdede",
   "metadata": {},
   "source": [
    "## SPARK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fffc58c-9353-489e-b798-8eb767c43590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the AGG is the key \n",
    "\n",
    "subreddits_authors = reddit_posts.groupBy(['subreddit']).agg(\\\n",
    "    count('*').alias('Total Messages'),\n",
    "    countDistinct('author').alias('Total Authors'),\n",
    "    mean(length('body')).alias('Message Average Length') )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdb8e1dc-a8d9-45cc-beaf-4cb94fcf4e0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reddit_with_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3v/cd3_rvz10bd1jd08x0c03tpr0000gt/T/ipykernel_3538/2718168122.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# EXPLODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreddit_with_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"words\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'reddit_with_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "# EXPLODE\n",
    "all_words = reddit_with_tokens.select(explode(\"words\").alias(\"word\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876288bc-8c55-486a-a6ca-cb29d71f9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_50k = filtered_tokens.rdd.map(lambda r: (r.subreddit, [r.word])).reduceByKey(lambda a,b: a+b).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
